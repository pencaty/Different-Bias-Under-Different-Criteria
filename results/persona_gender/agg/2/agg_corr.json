{
    "llama2_7b": {
        "2": {
            "slope": 0.01038155659389619,
            "intercept": -0.016958946020987412,
            "pearson": {
                "coefficient": 0.022508978985285186,
                "p_value": 0.8903491591723792
            }
        }
    },
    "llama2_7b_chat": {
        "2": {
            "slope": -0.27987709302396907,
            "intercept": 0.13892833142477648,
            "pearson": {
                "coefficient": -0.6114051070714468,
                "p_value": 2.7767528390626206e-05
            }
        }
    },
    "llama2_13b": {
        "2": {
            "slope": 0.011669503947514849,
            "intercept": -0.030105173605665576,
            "pearson": {
                "coefficient": 0.025251594348968412,
                "p_value": 0.8770851181373428
            }
        }
    },
    "llama2_13b_chat": {
        "2": {
            "slope": 0.08408456294338902,
            "intercept": -0.029689429456845443,
            "pearson": {
                "coefficient": 0.20816740186290375,
                "p_value": 0.19740062916939113
            }
        }
    },
    "llama3_8b": {
        "2": {
            "slope": -0.025586344603894855,
            "intercept": 0.020087948405004247,
            "pearson": {
                "coefficient": -0.07245801209140681,
                "p_value": 0.6568127007927435
            }
        }
    },
    "llama3_8b_instruct": {
        "2": {
            "slope": 0.005224510251447639,
            "intercept": -0.029871398018663856,
            "pearson": {
                "coefficient": 0.011594096035366833,
                "p_value": 0.943394099214888
            }
        }
    },
    "llama3.1_8b": {
        "2": {
            "slope": 0.10159276156064177,
            "intercept": -0.05072416811305201,
            "pearson": {
                "coefficient": 0.2287324185027514,
                "p_value": 0.1557071293459031
            }
        }
    },
    "llama3.1_8b_instruct": {
        "2": {
            "slope": 0.04411876802140623,
            "intercept": -0.04338659185474057,
            "pearson": {
                "coefficient": 0.10384451615871307,
                "p_value": 0.5236873304511612
            }
        }
    },
    "mistral_7b_v01": {
        "2": {
            "slope": 0.011828087941395785,
            "intercept": -0.030934743124595338,
            "pearson": {
                "coefficient": 0.02735182131005108,
                "p_value": 0.8669500029721788
            }
        }
    },
    "mistral_7b_plus": {
        "2": {
            "slope": 0.10667007782881867,
            "intercept": -0.07452171155060977,
            "pearson": {
                "coefficient": 0.2432821022067086,
                "p_value": 0.13035818683356118
            }
        }
    },
    "qwen1.5_7b": {
        "2": {
            "slope": -0.03801459848898368,
            "intercept": -0.009926175208152449,
            "pearson": {
                "coefficient": -0.09579278914533866,
                "p_value": 0.5565388604572501
            }
        }
    },
    "qwen1.5_7b_chat": {
        "2": {
            "slope": -0.35804848815132245,
            "intercept": 0.17890082892992604,
            "pearson": {
                "coefficient": -0.5255320027804243,
                "p_value": 0.0004972115387918022
            }
        }
    },
    "qwen2_7b": {
        "2": {
            "slope": -0.04702497303634026,
            "intercept": 0.037594780220983726,
            "pearson": {
                "coefficient": -0.13766138667875105,
                "p_value": 0.39694919632878817
            }
        }
    },
    "qwen2_7b_instruct": {
        "2": {
            "slope": -1.0058421992883873,
            "intercept": 0.4939313234929484,
            "pearson": {
                "coefficient": -0.8768456427979231,
                "p_value": 1.1932971524460397e-13
            }
        }
    },
    "gpt3.5": {
        "2": {
            "slope": 2.0852892756040875,
            "intercept": -1.046543894034351,
            "pearson": {
                "coefficient": 0.9132808204487263,
                "p_value": 2.110744850092848e-16
            }
        }
    },
    "gpt4": {
        "2": {
            "slope": 1.6222573073489226,
            "intercept": -0.832717603962322,
            "pearson": {
                "coefficient": 0.9046414821574258,
                "p_value": 1.1874571605187976e-15
            }
        }
    },
    "gpt4o_mini": {
        "2": {
            "slope": 1.9473010493704392,
            "intercept": -0.9825583015216179,
            "pearson": {
                "coefficient": 0.9385646666884868,
                "p_value": 3.7787011186066875e-19
            }
        }
    }
}