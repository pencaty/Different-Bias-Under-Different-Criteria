{
    "llama2_7b": {
        "1": {
            "slope": 0.013543598770229315,
            "intercept": -0.030295500682962558,
            "pearson": {
                "coefficient": 0.031003502936172544,
                "p_value": 0.8493788010699904
            }
        }
    },
    "llama2_7b_chat": {
        "1": {
            "slope": -0.062003713143458955,
            "intercept": 0.06711036306973053,
            "pearson": {
                "coefficient": -0.1329766601165825,
                "p_value": 0.41336199553984887
            }
        }
    },
    "llama2_13b": {
        "1": {
            "slope": 0.018049662198569943,
            "intercept": -0.03480641800813247,
            "pearson": {
                "coefficient": 0.04016710644455235,
                "p_value": 0.805618183692013
            }
        }
    },
    "llama2_13b_chat": {
        "1": {
            "slope": 0.22826807879434108,
            "intercept": -0.11503350853506064,
            "pearson": {
                "coefficient": 0.5911955570729697,
                "p_value": 5.8973087932451216e-05
            }
        }
    },
    "llama3_8b": {
        "1": {
            "slope": 0.12659646331409005,
            "intercept": -0.0967697754678447,
            "pearson": {
                "coefficient": 0.36680899896308117,
                "p_value": 0.019904354663844555
            }
        }
    },
    "llama3_8b_instruct": {
        "1": {
            "slope": 0.08813765441130735,
            "intercept": -0.03122306810087346,
            "pearson": {
                "coefficient": 0.17690938759315875,
                "p_value": 0.27481760689820794
            }
        }
    },
    "llama3.1_8b": {
        "1": {
            "slope": 0.19659596390593256,
            "intercept": -0.09239202488980167,
            "pearson": {
                "coefficient": 0.406397783219845,
                "p_value": 0.00926384579267832
            }
        }
    },
    "llama3.1_8b_instruct": {
        "1": {
            "slope": 0.19331914546883477,
            "intercept": -0.09574788123898785,
            "pearson": {
                "coefficient": 0.39334173915292425,
                "p_value": 0.012040397420306964
            }
        }
    },
    "mistral_7b_v01": {
        "1": {
            "slope": 0.03789281299092042,
            "intercept": -0.03076271891819432,
            "pearson": {
                "coefficient": 0.09262208088534296,
                "p_value": 0.5697347329448474
            }
        }
    },
    "mistral_7b_plus": {
        "1": {
            "slope": 0.1101808295607574,
            "intercept": -0.056533231232110036,
            "pearson": {
                "coefficient": 0.24755412684324923,
                "p_value": 0.12353461738502601
            }
        }
    },
    "qwen1.5_7b": {
        "1": {
            "slope": -0.00036710880351444367,
            "intercept": -0.03056580315783664,
            "pearson": {
                "coefficient": -0.0008506129176209798,
                "p_value": 0.9958437173230305
            }
        }
    },
    "qwen1.5_7b_chat": {
        "1": {
            "slope": 0.32750398431332695,
            "intercept": -0.14707512412921178,
            "pearson": {
                "coefficient": 0.6216333396816144,
                "p_value": 1.858854615830495e-05
            }
        }
    },
    "qwen2_7b": {
        "1": {
            "slope": 0.12101272965108895,
            "intercept": -0.029218137102433872,
            "pearson": {
                "coefficient": 0.3244626067550233,
                "p_value": 0.04108792763652769
            }
        }
    },
    "qwen2_7b_instruct": {
        "1": {
            "slope": 0.041951161386812645,
            "intercept": -0.026798995225833247,
            "pearson": {
                "coefficient": 0.08489391175275525,
                "p_value": 0.6024834705132409
            }
        }
    },
    "gpt3.5": {
        "1": {
            "slope": 1.7683394503531344,
            "intercept": -0.8992643192146853,
            "pearson": {
                "coefficient": 0.8859907735538102,
                "p_value": 2.9918957710000764e-14
            }
        }
    },
    "gpt4": {
        "1": {
            "slope": 1.5265242681699145,
            "intercept": -0.7909335515542547,
            "pearson": {
                "coefficient": 0.8712666843976379,
                "p_value": 2.6324688985352825e-13
            }
        }
    },
    "gpt4o_mini": {
        "1": {
            "slope": 1.9732474935405502,
            "intercept": -0.9960769298839711,
            "pearson": {
                "coefficient": 0.9408625094275747,
                "p_value": 1.8688036127495141e-19
            }
        }
    }
}