{
    "llama2_7b": {
        "1": {
            "slope": 0.2673109623539035,
            "intercept": -0.11398157515228483,
            "pearson": {
                "coefficient": 0.293495520719222,
                "p_value": 0.06605040348298157
            }
        }
    },
    "llama2_7b_chat": {
        "1": {
            "slope": 0.15119783034503545,
            "intercept": -0.07397242730149164,
            "pearson": {
                "coefficient": 0.16773490540220526,
                "p_value": 0.3008736408472646
            }
        }
    },
    "llama2_13b": {
        "1": {
            "slope": 0.23378677974127735,
            "intercept": -0.0971117544501604,
            "pearson": {
                "coefficient": 0.25977703329264346,
                "p_value": 0.1054894158710068
            }
        }
    },
    "llama2_13b_chat": {
        "1": {
            "slope": -0.07809035924148179,
            "intercept": 0.0412078391700209,
            "pearson": {
                "coefficient": -0.08020998184387224,
                "p_value": 0.6227191812177447
            }
        }
    },
    "llama3_8b": {
        "1": {
            "slope": 0.3294410125056501,
            "intercept": -0.18081286725930387,
            "pearson": {
                "coefficient": 0.44105950799642013,
                "p_value": 0.004389609419078349
            }
        }
    },
    "llama3_8b_instruct": {
        "1": {
            "slope": 0.19208334230181456,
            "intercept": -0.08582104651413076,
            "pearson": {
                "coefficient": 0.2166384130835648,
                "p_value": 0.17936799195749045
            }
        }
    },
    "llama3.1_8b": {
        "1": {
            "slope": 0.38532899976323204,
            "intercept": -0.1942703243720269,
            "pearson": {
                "coefficient": 0.3425836329405637,
                "p_value": 0.030468970205659338
            }
        }
    },
    "llama3.1_8b_instruct": {
        "1": {
            "slope": 0.2561075356766181,
            "intercept": -0.11767612303321208,
            "pearson": {
                "coefficient": 0.25809073626249174,
                "p_value": 0.10785201341722231
            }
        }
    },
    "mistral_7b_v01": {
        "1": {
            "slope": 0.28267935168643327,
            "intercept": -0.12428818958651719,
            "pearson": {
                "coefficient": 0.3048352517222156,
                "p_value": 0.055797830946581764
            }
        }
    },
    "mistral_7b_plus": {
        "1": {
            "slope": 0.1687724660453304,
            "intercept": -0.06172151789750107,
            "pearson": {
                "coefficient": 0.15916189367784073,
                "p_value": 0.3266026237049016
            }
        }
    },
    "qwen1.5_7b": {
        "1": {
            "slope": 0.046836996061043044,
            "intercept": -0.008315396370993763,
            "pearson": {
                "coefficient": 0.045558091934698966,
                "p_value": 0.78013520455446
            }
        }
    },
    "qwen1.5_7b_chat": {
        "1": {
            "slope": 0.10171333864267414,
            "intercept": -0.08772605953636536,
            "pearson": {
                "coefficient": 0.09415298282420842,
                "p_value": 0.5633455435041945
            }
        }
    },
    "qwen2_7b": {
        "1": {
            "slope": -0.19324565746141767,
            "intercept": 0.09844927785789624,
            "pearson": {
                "coefficient": -0.20125200570056798,
                "p_value": 0.21303763310164936
            }
        }
    },
    "qwen2_7b_instruct": {
        "1": {
            "slope": -0.3056027895563831,
            "intercept": 0.15917830775522504,
            "pearson": {
                "coefficient": -0.2788628812264967,
                "p_value": 0.08141915384854201
            }
        }
    },
    "gpt3.5": {
        "1": {
            "slope": 2.199046471082029,
            "intercept": -1.1913346176198367,
            "pearson": {
                "coefficient": 0.6781122727487566,
                "p_value": 1.5272280628063647e-06
            }
        }
    },
    "gpt4": {
        "1": {
            "slope": 1.258249208979961,
            "intercept": -0.803583697453669,
            "pearson": {
                "coefficient": 0.49229869728879994,
                "p_value": 0.0012519625733318728
            }
        }
    },
    "gpt4o_mini": {
        "1": {
            "slope": 1.8109408295486342,
            "intercept": -1.0160635183710367,
            "pearson": {
                "coefficient": 0.6318476694513263,
                "p_value": 1.2272351519908402e-05
            }
        }
    }
}