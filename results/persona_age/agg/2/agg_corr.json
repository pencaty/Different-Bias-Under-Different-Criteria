{
    "llama2_7b": {
        "2": {
            "slope": 0.23660647022105516,
            "intercept": -0.09913579715448032,
            "pearson": {
                "coefficient": 0.2713489492848618,
                "p_value": 0.09032526092119944
            }
        }
    },
    "llama2_7b_chat": {
        "2": {
            "slope": -0.35275188876213437,
            "intercept": 0.15991239587593362,
            "pearson": {
                "coefficient": -0.33049322463215036,
                "p_value": 0.03726295767899801
            }
        }
    },
    "llama2_13b": {
        "2": {
            "slope": 0.28771605071137996,
            "intercept": -0.13401052540950087,
            "pearson": {
                "coefficient": 0.31733538691783386,
                "p_value": 0.046013695078209245
            }
        }
    },
    "llama2_13b_chat": {
        "2": {
            "slope": -0.045943735336533356,
            "intercept": 0.01708258894939628,
            "pearson": {
                "coefficient": -0.05762770776988197,
                "p_value": 0.7239339673375206
            }
        }
    },
    "llama3_8b": {
        "2": {
            "slope": 0.35429088013086807,
            "intercept": -0.1764942207107342,
            "pearson": {
                "coefficient": 0.3647200420873935,
                "p_value": 0.020673826780240222
            }
        }
    },
    "llama3_8b_instruct": {
        "2": {
            "slope": 0.2199789061322887,
            "intercept": -0.09389859876450204,
            "pearson": {
                "coefficient": 0.24485012671275685,
                "p_value": 0.12782176933311135
            }
        }
    },
    "llama3.1_8b": {
        "2": {
            "slope": 0.682052992961536,
            "intercept": -0.36239964269571023,
            "pearson": {
                "coefficient": 0.526071662896796,
                "p_value": 0.0004894250347207731
            }
        }
    },
    "llama3.1_8b_instruct": {
        "2": {
            "slope": 0.19504294108784093,
            "intercept": -0.08617070965797802,
            "pearson": {
                "coefficient": 0.21563988202418663,
                "p_value": 0.18143022345129167
            }
        }
    },
    "mistral_7b_v01": {
        "2": {
            "slope": 0.23626208054413572,
            "intercept": -0.09594965453410537,
            "pearson": {
                "coefficient": 0.2615216655599639,
                "p_value": 0.10308678100505679
            }
        }
    },
    "mistral_7b_plus": {
        "2": {
            "slope": 0.35843431843130513,
            "intercept": -0.1599837491121204,
            "pearson": {
                "coefficient": 0.3465024035569757,
                "p_value": 0.028499698737370637
            }
        }
    },
    "qwen1.5_7b": {
        "2": {
            "slope": 0.0729568006199015,
            "intercept": -0.024183150735056756,
            "pearson": {
                "coefficient": 0.07876502663021188,
                "p_value": 0.6290183006481599
            }
        }
    },
    "qwen1.5_7b_chat": {
        "2": {
            "slope": -0.030876686971308073,
            "intercept": -0.011061150692007991,
            "pearson": {
                "coefficient": -0.025927264241590572,
                "p_value": 0.8738223315194129
            }
        }
    },
    "qwen2_7b": {
        "2": {
            "slope": -0.15491078154932303,
            "intercept": 0.02722927742740909,
            "pearson": {
                "coefficient": -0.17189665118733188,
                "p_value": 0.2888646712761017
            }
        }
    },
    "qwen2_7b_instruct": {
        "2": {
            "slope": -0.5556404571772963,
            "intercept": 0.3225736671043286,
            "pearson": {
                "coefficient": -0.4975113642623586,
                "p_value": 0.0010897704865552177
            }
        }
    },
    "gpt3.5": {
        "2": {
            "slope": 1.9160657784282915,
            "intercept": -1.0598835532404913,
            "pearson": {
                "coefficient": 0.6435812137017725,
                "p_value": 7.475313030548437e-06
            }
        }
    },
    "gpt4": {
        "2": {
            "slope": 0.8371790180589335,
            "intercept": -0.5297452592608536,
            "pearson": {
                "coefficient": 0.3857536155762553,
                "p_value": 0.013958128578890951
            }
        }
    },
    "gpt4o_mini": {
        "2": {
            "slope": 1.6047482726705267,
            "intercept": -0.9148664413784197,
            "pearson": {
                "coefficient": 0.6023461669340124,
                "p_value": 3.916644261044854e-05
            }
        }
    }
}