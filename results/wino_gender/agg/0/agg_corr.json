{
    "llama2_7b": {
        "0": {
            "slope": 0.09150121215997532,
            "intercept": -0.057160733201267626,
            "pearson": {
                "coefficient": 0.21566422141009545,
                "p_value": 0.18137975621223615
            }
        }
    },
    "llama2_7b_chat": {
        "0": {
            "slope": 0.09111570410855208,
            "intercept": -0.036967304536466,
            "pearson": {
                "coefficient": 0.2702136778537311,
                "p_value": 0.09173387230130295
            }
        }
    },
    "llama2_13b": {
        "0": {
            "slope": 0.18452693343239718,
            "intercept": -0.11008638884970529,
            "pearson": {
                "coefficient": 0.42545472782865157,
                "p_value": 0.0062024232921825155
            }
        }
    },
    "llama2_13b_chat": {
        "0": {
            "slope": 0.9207115076781814,
            "intercept": -0.46821699897752755,
            "pearson": {
                "coefficient": 0.8299313401006134,
                "p_value": 3.57676697036241e-11
            }
        }
    },
    "llama3_8b": {
        "0": {
            "slope": 0.16093471683995547,
            "intercept": -0.06799899417444767,
            "pearson": {
                "coefficient": 0.3890734364309078,
                "p_value": 0.013089464620349475
            }
        }
    },
    "llama3_8b_instruct": {
        "0": {
            "slope": 0.9921531588442118,
            "intercept": -0.4190628474500833,
            "pearson": {
                "coefficient": 0.8743286768751269,
                "p_value": 1.713116012361375e-13
            }
        }
    },
    "llama3.1_8b": {
        "0": {
            "slope": 0.4646221889672853,
            "intercept": -0.19087418331433542,
            "pearson": {
                "coefficient": 0.7582711226774441,
                "p_value": 1.4505678345707522e-08
            }
        }
    },
    "llama3.1_8b_instruct": {
        "0": {
            "slope": -0.09280580645217817,
            "intercept": 0.029565313387380405,
            "pearson": {
                "coefficient": -0.22426435808122858,
                "p_value": 0.16416796398977465
            }
        }
    },
    "mistral_7b_v01": {
        "0": {
            "slope": 0.026830484224397228,
            "intercept": -0.015712195459591308,
            "pearson": {
                "coefficient": 0.07431842502465158,
                "p_value": 0.6485643704839638
            }
        }
    },
    "mistral_7b_plus": {
        "0": {
            "slope": 0.05785074004403554,
            "intercept": -0.040026608817094834,
            "pearson": {
                "coefficient": 0.1541335269867643,
                "p_value": 0.34231282829609244
            }
        }
    },
    "qwen1.5_7b": {
        "0": {
            "slope": 0.07303625265146306,
            "intercept": -0.0366459397678716,
            "pearson": {
                "coefficient": 0.18166591438816376,
                "p_value": 0.26190958049495644
            }
        }
    },
    "qwen1.5_7b_chat": {
        "0": {
            "slope": -0.032879456013093264,
            "intercept": 0.016747267054569547,
            "pearson": {
                "coefficient": -0.0850644007441409,
                "p_value": 0.6017523075325466
            }
        }
    },
    "qwen2_7b": {
        "0": {
            "slope": -0.005474214330210429,
            "intercept": 0.008746687040183082,
            "pearson": {
                "coefficient": -0.01511320920316929,
                "p_value": 0.9262542855492152
            }
        }
    },
    "qwen2_7b_instruct": {
        "0": {
            "slope": -0.8585842567273345,
            "intercept": 0.3802946508129401,
            "pearson": {
                "coefficient": -0.8558572242618583,
                "p_value": 1.9602812944123882e-12
            }
        }
    },
    "gpt3.5": {
        "0": {
            "slope": 1.184329798633374,
            "intercept": -0.5962374764642955,
            "pearson": {
                "coefficient": 0.8795031147048444,
                "p_value": 8.075824210611124e-14
            }
        }
    },
    "gpt4": {
        "0": {
            "slope": 1.5374227560145828,
            "intercept": -0.7706518678303169,
            "pearson": {
                "coefficient": 0.9082951221318403,
                "p_value": 5.839975550561217e-16
            }
        }
    },
    "gpt4o_mini": {
        "0": {
            "slope": 2.0975764685885414,
            "intercept": -1.0507089931143008,
            "pearson": {
                "coefficient": 0.9272705195526125,
                "p_value": 8.445819255368744e-18
            }
        }
    }
}